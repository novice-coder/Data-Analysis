{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import sep, makedirs\n",
    "from os.path import dirname, realpath, join, isdir\n",
    "\n",
    "uppath = lambda _path, n: sep.join(_path.split(sep)[:-n]) # moves the path 'n' levels up the directory\n",
    "\n",
    "__file__ = dirname(realpath('__file__'))\n",
    "data_parent_directory = uppath(__file__, 2)\n",
    "data_directory = join(data_parent_directory, 'Data')\n",
    "titanic_directory = join(data_directory, 'titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Exracts the csv files from the 'titanic.zip' file and stores it in the 'titanic' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "def extract_titanic_data(zipfile_directory, titanic_directory):\n",
    "    \n",
    "    if not isdir(titanic_directory):\n",
    "        makedirs(titanic_directory)\n",
    "    \n",
    "    titanic_path = join(zipfile_directory, 'titanic.zip')\n",
    "    with ZipFile(titanic_path, 'r') as zip:\n",
    "            zip.extractall(path=titanic_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loads the extracted titanic data into two Pandas DFs: train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_titanic_data(titanic_directory):\n",
    "    train_csv = join(titanic_directory, \"train.csv\")\n",
    "    test_csv = join(titanic_directory, \"test.csv\")\n",
    "    return pd.read_csv(train_csv), pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "extract_titanic_data(data_directory, titanic_directory)\n",
    "\n",
    "train, test = load_titanic_data(titanic_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.00</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Master. Thomas Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Constance Gladys</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Stella Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. George John Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>847</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Douglas Bullen</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.00</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Mabel Helen</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.00</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "27            28         0       1     Fortune, Mr. Charles Alexander    male   \n",
       "159          160         0       3         Sage, Master. Thomas Henry    male   \n",
       "180          181         0       3       Sage, Miss. Constance Gladys  female   \n",
       "201          202         0       3                Sage, Mr. Frederick    male   \n",
       "792          793         0       3            Sage, Miss. Stella Anna  female   \n",
       "324          325         0       3           Sage, Mr. George John Jr    male   \n",
       "846          847         0       3           Sage, Mr. Douglas Bullen    male   \n",
       "341          342         1       1     Fortune, Miss. Alice Elizabeth  female   \n",
       "863          864         0       3  Sage, Miss. Dorothy Edith \"Dolly\"  female   \n",
       "88            89         1       1         Fortune, Miss. Mabel Helen  female   \n",
       "\n",
       "      Age  SibSp  Parch    Ticket    Fare        Cabin Embarked  \n",
       "27   19.0      3      2     19950  263.00  C23 C25 C27        S  \n",
       "159   NaN      8      2  CA. 2343   69.55          NaN        S  \n",
       "180   NaN      8      2  CA. 2343   69.55          NaN        S  \n",
       "201   NaN      8      2  CA. 2343   69.55          NaN        S  \n",
       "792   NaN      8      2  CA. 2343   69.55          NaN        S  \n",
       "324   NaN      8      2  CA. 2343   69.55          NaN        S  \n",
       "846   NaN      8      2  CA. 2343   69.55          NaN        S  \n",
       "341  24.0      3      2     19950  263.00  C23 C25 C27        S  \n",
       "863   NaN      8      2  CA. 2343   69.55          NaN        S  \n",
       "88   23.0      3      2     19950  263.00  C23 C25 C27        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[Outliers_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6284658040665434"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSize = train['Survived'].value_counts()[1] / train['Survived'].value_counts()[0]  \n",
    "trainSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    541\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].value_counts()\n",
    "train[train['Survived'] == 0]['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     1\n",
       "16     0\n",
       "17     1\n",
       "18     0\n",
       "19     1\n",
       "20     0\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     0\n",
       "25     1\n",
       "26     0\n",
       "27     1\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "851    0\n",
       "852    0\n",
       "853    1\n",
       "854    0\n",
       "855    1\n",
       "856    1\n",
       "857    0\n",
       "858    0\n",
       "859    1\n",
       "860    0\n",
       "861    1\n",
       "862    0\n",
       "863    0\n",
       "864    1\n",
       "865    1\n",
       "866    0\n",
       "867    0\n",
       "868    0\n",
       "869    1\n",
       "870    1\n",
       "871    0\n",
       "872    0\n",
       "873    0\n",
       "874    0\n",
       "875    0\n",
       "876    0\n",
       "877    1\n",
       "878    0\n",
       "879    1\n",
       "880    0\n",
       "Name: Survived, Length: 881, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 881 entries, 0 to 880\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    881 non-null int64\n",
      "Survived       881 non-null int64\n",
      "Pclass         881 non-null int64\n",
      "Name           881 non-null object\n",
      "Sex            881 non-null object\n",
      "Age            711 non-null float64\n",
      "SibSp          881 non-null int64\n",
      "Parch          881 non-null int64\n",
      "Ticket         881 non-null object\n",
      "Fare           881 non-null float64\n",
      "Cabin          201 non-null object\n",
      "Embarked       879 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 82.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There seem to be missing values in Cabin, Age and Embarked.  Age can be predicted with SibSp, Parch, Fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.034172\n",
       "Survived      -0.076867\n",
       "Pclass        -0.374495\n",
       "Age            1.000000\n",
       "SibSp         -0.307129\n",
       "Parch         -0.186457\n",
       "Fare           0.110219\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr().Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "Pclass and SibSp seem to have a weak correlation with Age. I'll nevertheless use them to try and predict it. I also want to consider the effects of Parch, although the data may suggest otherwise. \n",
    "\n",
    "#### So here's how I'll do it:\n",
    "I'll convert the numerical Age attribute into categorical: Young, middle-aged, old.\n",
    "Then I'll try to predict this new catgeory with the ones mentioned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extracts the part of the name between the comma (,) and the full-stop (.)\n",
    "def extract_title(x):\n",
    "    title = re.search('(.*), (.*?)\\.(.*)', x)\n",
    "    return title.group(2)\n",
    "\n",
    "train['Title']  = train['Name'].apply(lambda x: extract_title(x))\n",
    "test['Title'] = test['Name'].apply(lambda x: extract_title(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              513\n",
       "Miss            177\n",
       "Mrs             125\n",
       "Master           39\n",
       "Dr                7\n",
       "Rev               6\n",
       "Major             2\n",
       "Col               2\n",
       "Mlle              2\n",
       "Mme               1\n",
       "Jonkheer          1\n",
       "Ms                1\n",
       "Capt              1\n",
       "Lady              1\n",
       "Don               1\n",
       "the Countess      1\n",
       "Sir               1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def get_age_category(x):\n",
    "    if np.isnan(x):\n",
    "        return x\n",
    "    if x <=18:\n",
    "        return 1\n",
    "    elif x > 18 and x <= 50:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "train['Age_Category'] = train['Age'].apply(lambda x:  get_age_category(x))\n",
    "test['Age_Category'] = test['Age'].apply(lambda x: get_age_category(x))\n",
    "\n",
    "def get_name_category(x):\n",
    "    if x == 'Mr':\n",
    "        return 0\n",
    "    elif x == 'Miss':\n",
    "        return 1\n",
    "    elif x == 'Mrs':\n",
    "        return 2\n",
    "    elif x == 'Master':\n",
    "        return 3\n",
    "    elif type(x) == str:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "train['Name_Category'] = train['Title'].apply(lambda x:  get_name_category(x))\n",
    "test['Name_Category'] = test['Title'].apply(lambda x: get_name_category(x))\n",
    "\n",
    "\n",
    "#cats = {'a':1, 'p':2, 's':3, 'c':3, '1':2, '2':4, '3':5}\n",
    "cats = {'a':1, 'p':2, 's':1, 'c':1, '1':2, '2':1, '3':3}\n",
    "\n",
    "train['Ticket_Category'] = train['Ticket'].apply(lambda x: cats[x.lower()[0]] if x.lower()[0] in cats.keys() else 3)\n",
    "test['Ticket_Category'] = test['Ticket'].apply(lambda x: cats[x.lower()[0]] if x.lower()[0] in cats.keys() else 3)\n",
    "\n",
    "train['Ticket_Category'] = train['Ticket'].apply(lambda x: 1 if x.lower()[0]  == 'a' else 0)\n",
    "test['Ticket_Category'] = test['Ticket'].apply(lambda x: 1 if x.lower()[0] == 'a' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>Name_Category</th>\n",
       "      <th>Ticket_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Title  Age_Category  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S    Mr           2.0   \n",
       "1      0          PC 17599  71.2833   C85        C   Mrs           2.0   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  Miss           2.0   \n",
       "3      0            113803  53.1000  C123        S   Mrs           2.0   \n",
       "4      0            373450   8.0500   NaN        S    Mr           2.0   \n",
       "\n",
       "   Name_Category  Ticket_Category  \n",
       "0              0                1  \n",
       "1              2                0  \n",
       "2              1                0  \n",
       "3              2                0  \n",
       "4              0                0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loading non-null Age data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVINASH AKELLA\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\AVINASH AKELLA\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\AVINASH AKELLA\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\avinash akella\\canopy\\notebooks\\practice:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7762237762237763"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_not_null = train[~np.isnan(train['Age'])]\n",
    "\n",
    "age_null = train[np.isnan(train['Age'])]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(age_not_null, age_not_null[\"Age_Category\"]):\n",
    "    strat_train_set = age_not_null.iloc[train_index]\n",
    "    strat_test_set = age_not_null.iloc[test_index]\n",
    "\n",
    "predictors = ['Pclass', 'Name_Category']\n",
    "targets = ['Age_Category']\n",
    "\n",
    "\n",
    "age_train_pred = prepare_age_data(strat_train_set[predictors])\n",
    "age_train_tar = strat_train_set[targets]\n",
    "\n",
    "age_test_pred = prepare_age_data(strat_test_set[predictors])\n",
    "age_test_tar = strat_test_set[targets]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "#forest_clf =  GradientBoostingClassifier(subsample = 0.75, random_state=42)\n",
    "scores = cross_val_score(forest_clf, age_train_pred, age_train_tar, cv=3, scoring=\"accuracy\")\n",
    "scores.mean()\n",
    "\n",
    "'''The Accuracy is low. But that is expected, considering the low correlation. I'll anyway continue with the imputation and see how it goes. But it sure needs improvement.'''\n",
    "\n",
    "forest_clf.fit(age_train_pred, age_train_tar)\n",
    "result = forest_clf.predict(age_test_pred)\n",
    "\n",
    "accuracy_score(age_test_tar, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "def prepare_age_data(X):\n",
    "    \n",
    "    encoded = pd.get_dummies(X, columns=[ 'Name_Category'])\n",
    "    for i in range(1, 6):\n",
    "        if 'Name_Category_'+str(i) not in encoded.columns:\n",
    "            encoded['Name_Category_'+str(i)] = 0\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "\n",
    "def predict_age_category(X):\n",
    "    predictors = ['Pclass', 'Name_Category']\n",
    "    targets = ['Age_Category']\n",
    "\n",
    "    age_not_null = train[~np.isnan(train['Age_Category'])]\n",
    "    age_train_pred = prepare_age_data(age_not_null[predictors])\n",
    "    age_train_tar = age_not_null[targets]\n",
    "    \n",
    "    forest_clf = RandomForestClassifier(n_estimators=10, random_state=42, bootstrap=False)\n",
    "    forest_clf.fit(age_train_pred, age_train_tar)\n",
    "    \n",
    "    age_null = X[np.isnan(X['Age_Category'])]\n",
    "    age_test_pred = prepare_age_data(age_null[predictors])\n",
    "    \n",
    "    predictions = forest_clf.predict(age_test_pred)\n",
    "    X.drop(['Name_Category', 'Pclass'], axis=1, inplace=True)\n",
    "    \n",
    "    return predictions \n",
    "\n",
    "\n",
    "class Age_Imputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        age_result_category = predict_age_category(X)\n",
    "        #X.drop('Fare', axis=1, inplace=True)\n",
    "\n",
    "        young_median = X[X['Age'] <= 18].median().Age\n",
    "        middle_aged_median = X[X['Age'] > 18][X['Age'] <= 50].median().Age\n",
    "        old_median = X[X['Age'] > 50].median().Age\n",
    "\n",
    "        age_map = {1:young_median, 2:middle_aged_median, 3:old_median}\n",
    "\n",
    "        result_pos = -1\n",
    "        for index, row in X.iterrows():\n",
    "            if np.isnan(row['Age']):\n",
    "                result_pos += 1\n",
    "                X.at[index, 'Age'] = age_map[age_result_category[result_pos]]\n",
    "        return X\n",
    "    \n",
    "class Age_Category_Imputer(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self): # no *args or **kargs\n",
    "            pass\n",
    "        def fit(self, X, y=None):\n",
    "            return self  # nothing else to do\n",
    "        def transform(self, X, y=None):\n",
    "\n",
    "            age_result_category = predict_age_category(X)\n",
    "            #X.drop(['Fare', 'Parch'], axis=1, inplace=True)\n",
    "        \n",
    "            result_pos = -1\n",
    "            for index, row in X.iterrows():\n",
    "                if np.isnan(row['Age_Category']):\n",
    "                    result_pos += 1\n",
    "                    X.at[index, 'Age_Category'] = age_result_category[result_pos]\n",
    "            return X\n",
    "        \n",
    "class Child_Or_Old(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        age_result_category = predict_age_category(X)\n",
    "            \n",
    "        result_pos = -1\n",
    "        for index, row in X.iterrows():\n",
    "            if np.isnan(row['Age_Category']):\n",
    "                result_pos += 1\n",
    "                X.at[index, 'Age_Category'] = age_result_category[result_pos]\n",
    "                \n",
    "        X['Child_Or_Old'] = X['Age_Category'].apply(lambda x: 0 if x == 2 else 1)\n",
    "        X.drop(['Age_Category'], axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class Embarked_Imputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        embarked_mode = X['Embarked'].mode()[0]\n",
    "        for index, row in X.iterrows():\n",
    "            if not isinstance(row['Embarked'], str):\n",
    "                X.at[index, 'Embarked'] = embarked_mode\n",
    "        X['Embarked'] = X['Embarked'].apply(lambda x: 1 if x == 'S' else 0)\n",
    "        return X\n",
    "\n",
    "\n",
    "class Parch_Transform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        X['Parch_Transformed'] = X['Parch'].apply(lambda x: 1 if x == 0 else 0)\n",
    "        X.drop('Parch', inplace=True, axis=1)\n",
    "        return X\n",
    "        \n",
    "        \n",
    "class SibSp_Transform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        X['SibSp_Transformed'] = X['SibSp'].apply(lambda x: 1 if x == 0 else 0)\n",
    "        X.drop('SibSp', inplace=True, axis=1)\n",
    "        return X\n",
    "\n",
    "class SibSp_Parch_Transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        X['Parch_SibSp_Transformed'] = X[['Parch', 'SibSp']].apply(lambda x: 1 if x['SibSp'] == 0 and x['Parch'] == 0 else 0, axis=1)\n",
    "        X.drop(['SibSp', 'Parch'], inplace=True, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    #('sibsp_transformer', SibSp_Transform()),\n",
    "    #('parch_transformer', Parch_Transform()),\n",
    "    #('sibsp_parch_transformer', SibSp_Parch_Transformer()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"embarked_imputer\", Embarked_Imputer()),\n",
    "    (\"age_category_imputer\", Age_Category_Imputer()),\n",
    "    (\"one_hot_encoding\", OneHotEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "age_predictors = [ 'Pclass', 'Name_Category']\n",
    "num_attribs = [ 'Family_Size']\n",
    "cat_attribs = ['Embarked', 'Sex', 'Age_Category', 'Ticket_Category', 'Cabin_Category']\n",
    "cat_total_attribs = cat_attribs + age_predictors                   # Age_Category, Name_Category, Fare, Parch and Sex are used \n",
    "                                                                   # only for creating Child_Or_Old and Female columns\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"categorical\", cat_pipeline, cat_total_attribs),\n",
    "        (\"numerical\", num_pipeline, num_attribs)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\avinash akella\\canopy\\notebooks\\practice:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "age_not_null = train[~np.isnan(train['Age'])]\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(age_not_null, age_not_null['Age_Category']):\n",
    "    not_null_train = train.iloc[train_index]\n",
    "    not_null_test = train.iloc[test_index]\n",
    "    \n",
    "age_null = train[np.isnan(train['Age'])]\n",
    "null_train, null_test = train_test_split(age_null, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "total_train = [not_null_train, null_train]\n",
    "total_test = [not_null_test, null_test]\n",
    "\n",
    "strat_train_set = pd.concat(total_train, ignore_index=True)\n",
    "strat_test_set = pd.concat(total_test, ignore_index=True)\n",
    "\n",
    "def survived_category_equalizer(train_data):\n",
    "    \n",
    "    trainSize = train_data['Survived'].value_counts()[1] / train_data['Survived'].value_counts()[0]\n",
    "    \n",
    "    trainSplit = StratifiedShuffleSplit(n_splits=1, train_size=trainSize, random_state=42)\n",
    "    for train_index, test_index in split.split(train_data[train['Survived'] == 0], train_data[train_data['Survived'] == 0][['Age_Category','SibSp','Parch','Fare']]):\n",
    "        updated_train_data = train_data.iloc[train_index]\n",
    "    \n",
    "    return updated_train_data\n",
    "    \n",
    "\n",
    "# train_prepared = full_pipeline.fit_transform(strat_train_set[num_attribs + cat_attribs + age_predictors])\n",
    "# train_prepared = survived_category_equalizer(train_prepared)\n",
    "train_labels = strat_train_set['Survived'].copy()\n",
    "\n",
    "test_prepared = full_pipeline.fit_transform(strat_test_set[num_attribs + cat_attribs + age_predictors])\n",
    "test_labels = strat_test_set['Survived'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_null_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\avinash akella\\canopy\\notebooks\\practice:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "c:\\users\\avinash akella\\canopy\\notebooks\\practice:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\AVINASH AKELLA\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:523: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\AVINASH AKELLA\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:528: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "final_train_prepared = full_pipeline.fit_transform(train[num_attribs + cat_attribs + age_predictors])\n",
    "final_test_prepared = full_pipeline.fit_transform(test[num_attribs + cat_attribs + age_predictors])\n",
    "final_train_labels = train['Survived'].copy()\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=10, random_state=42, oob_score=True) \n",
    "forest_clf.fit(final_train_prepared, final_train_labels)\n",
    "final_result = forest_clf.predict(final_test_prepared)\n",
    "submission_data = {'PassengerId': test['PassengerId'], 'Survived': final_result}\n",
    "submission = pd.DataFrame(data=submission_data)\n",
    "\n",
    "submission.to_csv(path_or_buf=join(titanic_directory, \"submission.csv\"), index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    260\n",
       "1    158\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Testing accuracy with train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVINASH AKELLA\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:523: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\AVINASH AKELLA\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:528: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=10, random_state=42, oob_score=True) \n",
    "forest_clf.fit(final_train_prepared, final_train_labels)\n",
    "final_result = forest_clf.predict(final_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7922814982973894"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.feature_importances_\n",
    "forest_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Further Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(train[train['Embarked'] == 'S'].SibSp.value_counts())\n",
    "# print(train[train['Embarked'] == 'C'].SibSp.value_counts())\n",
    "# print(train[train['Embarked'] == 'Q'].SibSp.value_counts())\n",
    "\n",
    "counts = {}\n",
    "count = 0\n",
    "non_null = 0\n",
    "for index, row in train.iterrows():\n",
    "    if isinstance(row['Cabin'], str):\n",
    "        non_null += 1\n",
    "        count = len(row['Cabin'].split(' '))\n",
    "        if count in counts.keys():\n",
    "            counts[count] += 1\n",
    "        else:\n",
    "            counts[count] = 1\n",
    "print(count, non_null, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train['Cabin'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cabin_category(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x[0]\n",
    "        if x == 'A' or x == 'G' or x == 'T':\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "train['Cabin_Category'] = train['Cabin'].apply(lambda x: get_cabin_category(x))\n",
    "test['Cabin_Category'] = test['Cabin'].apply(lambda x: get_cabin_category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    680\n",
       "2    181\n",
       "1     20\n",
       "Name: Cabin_Category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cabin_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train['Family_Size'] = train[['Parch', 'SibSp']].apply(lambda x:  x['SibSp'] + x['Parch'] + 1, axis=1)\n",
    "test['Family_Size'] = test[['Parch', 'SibSp']].apply(lambda x:  x['SibSp'] + x['Parch'] + 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
